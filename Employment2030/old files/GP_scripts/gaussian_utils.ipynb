{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0818 18:45:05.554438 4611364288 deprecation_wrapper.py:119] From /Users/rob/.pyenv/versions/brookfield/lib/python3.5/site-packages/gpflow/session_manager.py:31: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "W0818 18:45:05.559500 4611364288 deprecation_wrapper.py:119] From /Users/rob/.pyenv/versions/brookfield/lib/python3.5/site-packages/gpflow/misc.py:27: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "W0818 18:45:05.779114 4611364288 deprecation_wrapper.py:119] From /Users/rob/.pyenv/versions/brookfield/lib/python3.5/site-packages/gpflow/training/tensorflow_optimizer.py:169: The name tf.train.AdadeltaOptimizer is deprecated. Please use tf.compat.v1.train.AdadeltaOptimizer instead.\n",
      "\n",
      "W0818 18:45:05.780936 4611364288 deprecation_wrapper.py:119] From /Users/rob/.pyenv/versions/brookfield/lib/python3.5/site-packages/gpflow/training/tensorflow_optimizer.py:156: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0818 18:45:05.782598 4611364288 deprecation_wrapper.py:119] From /Users/rob/.pyenv/versions/brookfield/lib/python3.5/site-packages/gpflow/training/tensorflow_optimizer.py:169: The name tf.train.AdagradDAOptimizer is deprecated. Please use tf.compat.v1.train.AdagradDAOptimizer instead.\n",
      "\n",
      "W0818 18:45:05.784300 4611364288 deprecation_wrapper.py:119] From /Users/rob/.pyenv/versions/brookfield/lib/python3.5/site-packages/gpflow/training/tensorflow_optimizer.py:169: The name tf.train.AdagradOptimizer is deprecated. Please use tf.compat.v1.train.AdagradOptimizer instead.\n",
      "\n",
      "W0818 18:45:05.785412 4611364288 deprecation_wrapper.py:119] From /Users/rob/.pyenv/versions/brookfield/lib/python3.5/site-packages/gpflow/training/tensorflow_optimizer.py:169: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "W0818 18:45:05.799882 4611364288 deprecation_wrapper.py:119] From /Users/rob/.pyenv/versions/brookfield/lib/python3.5/site-packages/gpflow/saver/coders.py:80: The name tf.data.Iterator is deprecated. Please use tf.compat.v1.data.Iterator instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%run utils.ipynb\n",
    "\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "import gpflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, roc_auc_score\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "from ordinal_likelihood import Ordinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "datasets = {'agg': {'x': {'cont':         x_cont_agg, \n",
    "                          'disc':         x_disc_agg}, \n",
    "                    'y': {# 'abs':          y_abs_agg['y'],\n",
    "                          # 'abs_binned':   y_abs_agg['binned_y'],\n",
    "                          'share':        y_share_agg['y'],\n",
    "                          'share_binned': y_share_agg['binned_y']}\n",
    "                   },\n",
    "            'ind': {'x': {'cont':         x_cont_ind,\n",
    "                          'disc':         x_disc_ind},\n",
    "                    'y': {# 'abs':          y_abs_ind,\n",
    "                          # 'abs_binned':   y_abs_bin_ind,\n",
    "                          'share':        y_share_ind,\n",
    "                          'share_binned': y_share_bin_ind}\n",
    "                   }\n",
    "           }\n",
    "\n",
    "kernels = ['Matern12', 'Matern32', 'Matern52', 'RBF']\n",
    "\n",
    "agg_level = 'both'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rec_dd():\n",
    "        return defaultdict(rec_dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kern(kern):\n",
    "    if kern == 'Matern12': return gpflow.kernels.Matern12(1)\n",
    "    if kern == 'Matern32': return gpflow.kernels.Matern32(1) \n",
    "    if kern == 'Matern52': return gpflow.kernels.Matern52(1)\n",
    "    if kern == 'RBF':      return gpflow.kernels.RBF(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create x and y arrays\n",
    "def x_and_y(x, y):\n",
    "    change = {'decrease':     2,\n",
    "              'constant':     1, \n",
    "              'increase':     0,\n",
    "              'fewer':        2,\n",
    "              'same':         1,\n",
    "              'more':         0,\n",
    "              'not_increase': 1}\n",
    "    x = np.array(x)\n",
    "    y = np.array(pd.Series(y).replace(change).values.astype('int64')).reshape(y.shape[0], 1)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get bin edges and likelihood\n",
    "def create_likelihood(y):\n",
    "    bin_edges = np.array(np.arange(np.unique(y).size + 1), dtype=float)\n",
    "    # Need to check in on this, tutorial does the below which ends up with negative bins\n",
    "    # bin_edges = bin_edges - bin_edges.mean()\n",
    "    bin_edges = bin_edges - .5\n",
    "    return Ordinal(bin_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a model with this likelihood\n",
    "def build_model(x_train, y_train, likelihood, kernel):\n",
    "    gaussian_model = gpflow.models.VGP(tf.cast(x_train, tf.float64),\n",
    "                                       y_train, \n",
    "                                       kern=kernel,\n",
    "                                       likelihood=likelihood)\n",
    "    # fit the model\n",
    "    gpflow.train.ScipyOptimizer().minimize(gaussian_model)\n",
    "    return gaussian_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictive densities\n",
    "def test_model(model, x_test):\n",
    "    densities = []\n",
    "    # Predictive density for a single input x\n",
    "    for x in x_test:\n",
    "        ys = np.arange(np.max(model.Y.value+1)).reshape([-1, 1])\n",
    "        x_new_vec = x*np.ones_like(ys)\n",
    "        # for predict_density x and y need to have the same number of rows\n",
    "        dens = np.exp(model.predict_density(x_new_vec, ys))\n",
    "        densities.append(dens)\n",
    "    return densities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get accuracy\n",
    "def accuracy(y_test, densities):\n",
    "    score = 0\n",
    "    for index, y in enumerate(y_test):\n",
    "        if y == np.argmax(densities[index]): score += 1\n",
    "    return score/len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiclass ROC\n",
    "def multiclass_roc_auc_score(y_test, y_pred, average=\"macro\"):\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(y_test)\n",
    "    y_test = lb.transform(y_test)\n",
    "    y_pred = lb.transform(y_pred)\n",
    "    return roc_auc_score(y_test, y_pred, average=average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure out the mse\n",
    "def scale_pred(pred):\n",
    "    factor = 1/sum(pred)\n",
    "    scaled = []\n",
    "    for p in pred:\n",
    "        scaled.append(p * factor)\n",
    "    return tuple(scaled)\n",
    "\n",
    "def calc_errors(x_test_all, densities, agg_level, dist):\n",
    "    mapping = {0: 'increase',\n",
    "               1: 'constant/not increase',\n",
    "               2: 'decrease'}\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    true_class = []\n",
    "    pred_class = []\n",
    "    # true then pred\n",
    "    confusion = defaultdict(lambda: defaultdict(int))\n",
    "    for index, x in enumerate(x_test_all.iterrows()):\n",
    "        x = tuple(x[1].values)\n",
    "        pred = tuple([p for [p] in densities[index]])\n",
    "        pred = scale_pred(pred)\n",
    "        if agg_level == 'ind': x = tuple(list(x[1:]) + [x[0]])\n",
    "        true_info = noc_dict[dist][x]\n",
    "        noc = true_info['noc']\n",
    "        if len(pred) == 3: true_dist = true_info['share']\n",
    "        else:              true_dist = true_info['share_binned']\n",
    "        y_true.append(true_dist)\n",
    "        y_pred.append(pred)\n",
    "        y_t = np.argmax(true_dist)\n",
    "        y_p = np.argmax(pred)\n",
    "        true_class.append(y_t)\n",
    "        pred_class.append(y_p)\n",
    "        confusion[mapping[y_t]][mapping[y_p]] += 1\n",
    "        \n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    roc = multiclass_roc_auc_score(true_class, pred_class)\n",
    "    return mse, roc, confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do cross validation\n",
    "def cv(x, y, x_all, y_all, kern, agg_level, dist):\n",
    "    if agg_level == 'ind': x_all = x_all.drop(['noc', 'participant.id'], axis=1)\n",
    "    kf = KFold(n_splits=5)\n",
    "    scores = []\n",
    "    results = []\n",
    "    mse = []\n",
    "    roc = []\n",
    "    total_confusion = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "    for train_index, test_index in kf.split(x):\n",
    "        start = time.time()\n",
    "        x_train, x_test = x[train_index], x[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        x_test_all = x_all.iloc[test_index]\n",
    "        kernel = get_kern(kern)\n",
    "        likelihood = create_likelihood(y_all)\n",
    "        model = build_model(x_train, y_train, likelihood, kernel)\n",
    "        densities = test_model(model, x_test)\n",
    "        scores.append(accuracy(y_test, densities))\n",
    "        mse_error, roc_error, confusion = calc_errors(x_test_all, densities, agg_level, dist)\n",
    "        mse.append(mse_error)\n",
    "        roc.append(roc_error)\n",
    "        for y_t in confusion:\n",
    "            for y_p in confusion[y_t]:\n",
    "                total_confusion[y_t][y_p] += confusion[y_t][y_p]\n",
    "        results.append(create_results(x_test, densities))\n",
    "        end = time.time()\n",
    "        print('Fold tested in (sec):', end - start)\n",
    "        del kernel, likelihood, model\n",
    "\n",
    "    return {'Avg. score':  sum(scores)/len(scores),\n",
    "            'Avg. mse':    sum(mse)/len(mse),\n",
    "            'Avg. roc':    sum(roc)/len(roc),\n",
    "            'Confusion':   dict(total_confusion),\n",
    "            'All scores':  scores,\n",
    "            'All mse':     mse,\n",
    "            'All roc':     roc,\n",
    "            'All results': results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickle_results(results, params):\n",
    "    with open('gp_results/{}.pkl'.format(params), 'wb') as f:\n",
    "        pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def organize_results(results):\n",
    "    best_result = {'Matern12': ['', 0],\n",
    "                   'Matern32': ['', 0],\n",
    "                   'Matern52': ['', 0],\n",
    "                   'RBF':      ['', 0]}\n",
    "\n",
    "    for kern in results:\n",
    "        for agg_name in results[kern]:\n",
    "            for var_type in results[kern][agg_name]:\n",
    "                for result_dist in results[kern][agg_name][var_type]:\n",
    "                    params = ' '.join([kern, agg_name, var_type, result_dist])\n",
    "                    score = results[kern][agg_name][var_type][result_dist]['Avg. score']\n",
    "                    if score == best_result[kern][1]: \n",
    "                        best_result[kern][0] += ', ' + params\n",
    "                    if score > best_result[kern][1]: \n",
    "                        best_result[kern] = [params, score]\n",
    "        \n",
    "    return best_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_results(x_test, densities):\n",
    "    results = {}\n",
    "    for index, x in enumerate(x_test):\n",
    "        results[(tuple(x))] = densities[index]\n",
    "    return results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brookfield",
   "language": "python",
   "name": "brookfield"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
