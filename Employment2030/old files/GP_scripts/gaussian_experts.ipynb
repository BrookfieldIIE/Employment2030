{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note\n",
    "\n",
    "This code was used for exploratory purposes early on in our analysis. The intention was to see if modeling each expert as a gaussian process could provide predictions for new nocs. We decided to not go down these route due to the severly decreased accuracy compared to our main gaussian process model. However, that does not mean that this approach will not work. We just did not prioritize trying to make it work. As such, this code is provided as-is. It currently does not work and will probably require some significant changes to make it work. Additionally, when running the models, we could only run one model before having to restart our kernel in order to prevent the kernel from dying for the second model. Also note that this code uses multiprocessing which can make debugging difficult."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../utils/gaussian_utils.ipynb\n",
    "\n",
    "from pathos.multiprocessing import ProcessingPool as Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_with_experts(x_all, y_all, kern, name, agg_level, dist):\n",
    "    params = '_'.join([name, 'gp_experts'])\n",
    "    print('Testing:', params)\n",
    "    start = time.time()\n",
    "    x, y = x_and_y(x_all, y_all)\n",
    "    result = cv_experts(x, y, x_all, y_all, kern, agg_level, dist)\n",
    "    end = time.time()\n",
    "    print('Accuracy:', result['Avg. score'])\n",
    "    print('MSE:', result['Avg. mse'])\n",
    "    print('ROC:', result['Avg. roc'])\n",
    "    print('Confusion:', result['Confusion'])\n",
    "    print('Time elapsed (sec):', end - start)\n",
    "    pickle_results(result, params)\n",
    "    print('Results saved to disk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do cross validation\n",
    "def cv_experts(x, y, x_all, y_all, kern, agg_level, dist):\n",
    "    x_all = np.asarray(x_all.drop(['noc', 'participant.id'], axis=1))\n",
    "    group = x_cont_ind['noc']\n",
    "    kf = GroupKFold(n_splits=5)\n",
    "    scores = []\n",
    "    results = []\n",
    "    mse = []\n",
    "    roc = []\n",
    "    total_confusion = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "    for train_index, test_index in kf.split(x, groups=group):\n",
    "        start = time.time()\n",
    "        x_train, x_test = x[train_index], x[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        x_test_all = x_all[test_index]\n",
    "        densities, unique_indices = gp_experts(x_train, y_train, y_all, kern, x_test)\n",
    "        scores.append(accuracy([y_test[i] for i in unique_indices], densities))\n",
    "        mse_error, roc_error, confusion = calc_errors([x_test_all[i] for i in unique_indices], \n",
    "                                                      densities, \n",
    "                                                      agg_level, \n",
    "                                                      dist)\n",
    "        mse.append(mse_error)\n",
    "        roc.append(roc_error)\n",
    "        for y_t in confusion:\n",
    "            for y_p in confusion[y_t]:\n",
    "                total_confusion[y_t][y_p] += confusion[y_t][y_p]\n",
    "        results.append(create_results([x_test[i] for i in unique_indices], densities))\n",
    "        end = time.time()\n",
    "        print('Fold tested in (sec):', end - start)\n",
    "\n",
    "    return {'Avg. score':  sum(scores)/len(scores),\n",
    "            'Avg. mse':    sum(mse)/len(mse),\n",
    "            'Avg. roc':    sum(roc)/len(roc),\n",
    "            'Confusion':   dict(total_confusion),\n",
    "            'All scores':  scores,\n",
    "            'All mse':     mse,\n",
    "            'All roc':     roc,\n",
    "            'All results': results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gp_experts(x_train, y_train, y_all, kern, x_test):\n",
    "    def tester(model):\n",
    "        densities = test_model(model, [x_test[i] for i in unique_indices])\n",
    "        preds = [np.argmax(d) for d in densities]\n",
    "        return preds\n",
    "    \n",
    "    def builder(params):\n",
    "        expert, data = params\n",
    "        kernel = get_kern(kern)\n",
    "        likelihood = create_likelihood(y_all)\n",
    "        model = build_model(np.asarray(data),\n",
    "                            ys[workshop][expert],\n",
    "                            likelihood,\n",
    "                            kernel)\n",
    "        preds = tester(model)\n",
    "        classes = np.max(model.Y.value + 1)\n",
    "        del model\n",
    "        return workshop, expert, classes, preds\n",
    "    # Done to drop the first 3 rows of the data (workshop num, noc name and participant id)\n",
    "    # Set up test data\n",
    "    x_test = np.asarray([np.asarray(x[3:]).astype(float) for x in x_test])\n",
    "    unique, unique_indices = np.unique(x_test, axis=0, return_index=True)\n",
    "    # Set up training data\n",
    "    xs = defaultdict(lambda: defaultdict(list))\n",
    "    ys = defaultdict(lambda: defaultdict(list))\n",
    "    for index, x in enumerate(x_train):\n",
    "        xs[x[0]][x[2]].append(np.asarray(x[3:]).astype(float))\n",
    "        ys[x[0]][x[2]].append(y_train[index])\n",
    "    for workshop in xs:\n",
    "        with Pool() as pool:\n",
    "            results = pool.map(builder, xs[workshop].items())\n",
    "    experts = 0\n",
    "    densities = []\n",
    "    for i in range(len(results[0][3])):\n",
    "        density = []\n",
    "        for j in range(int(results[0][2])):\n",
    "            density.append([0])\n",
    "        densities.append(density)\n",
    "    for workshop, expert, classes, preds in results:\n",
    "        experts += 1\n",
    "        for index, pred in enumerate(preds):\n",
    "            densities[index][pred][0] += 1\n",
    "    for row in densities:\n",
    "        for d in row:\n",
    "            d[0] = d[0] / experts\n",
    "    return densities, unique_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run through - experts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scratchpad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_python3)",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
