{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0903 11:21:21.502460 4534601152 deprecation_wrapper.py:119] From /Users/rob/.pyenv/versions/brookfield/lib/python3.5/site-packages/gpflow/session_manager.py:31: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "W0903 11:21:21.513328 4534601152 deprecation_wrapper.py:119] From /Users/rob/.pyenv/versions/brookfield/lib/python3.5/site-packages/gpflow/misc.py:27: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "W0903 11:21:21.617810 4534601152 deprecation_wrapper.py:119] From /Users/rob/.pyenv/versions/brookfield/lib/python3.5/site-packages/gpflow/training/tensorflow_optimizer.py:169: The name tf.train.AdadeltaOptimizer is deprecated. Please use tf.compat.v1.train.AdadeltaOptimizer instead.\n",
      "\n",
      "W0903 11:21:21.619091 4534601152 deprecation_wrapper.py:119] From /Users/rob/.pyenv/versions/brookfield/lib/python3.5/site-packages/gpflow/training/tensorflow_optimizer.py:156: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0903 11:21:21.620031 4534601152 deprecation_wrapper.py:119] From /Users/rob/.pyenv/versions/brookfield/lib/python3.5/site-packages/gpflow/training/tensorflow_optimizer.py:169: The name tf.train.AdagradDAOptimizer is deprecated. Please use tf.compat.v1.train.AdagradDAOptimizer instead.\n",
      "\n",
      "W0903 11:21:21.630403 4534601152 deprecation_wrapper.py:119] From /Users/rob/.pyenv/versions/brookfield/lib/python3.5/site-packages/gpflow/training/tensorflow_optimizer.py:169: The name tf.train.AdagradOptimizer is deprecated. Please use tf.compat.v1.train.AdagradOptimizer instead.\n",
      "\n",
      "W0903 11:21:21.638422 4534601152 deprecation_wrapper.py:119] From /Users/rob/.pyenv/versions/brookfield/lib/python3.5/site-packages/gpflow/training/tensorflow_optimizer.py:169: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "W0903 11:21:21.660725 4534601152 deprecation_wrapper.py:119] From /Users/rob/.pyenv/versions/brookfield/lib/python3.5/site-packages/gpflow/saver/coders.py:80: The name tf.data.Iterator is deprecated. Please use tf.compat.v1.data.Iterator instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%run ../../utils.ipynb\n",
    "# %run objects.ipynb\n",
    "\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "import gpflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import mean_squared_error, roc_auc_score, mean_absolute_error\n",
    "from sklearn.preprocessing import LabelBinarizer, scale, robust_scale, normalize\n",
    "\n",
    "from ordinal_likelihood import Ordinal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rec_dd():\n",
    "        return defaultdict(rec_dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Moved\n",
    "def get_kern(kern, dims, shape):\n",
    "    kern = kern.split('_')\n",
    "    with gpflow.defer_build():\n",
    "        if kern[0] == 'Matern12': kernel = gpflow.kernels.Matern12(input_dim=dims)\n",
    "        if kern[0] == 'Matern32': kernel = gpflow.kernels.Matern32(input_dim=dims) \n",
    "        if kern[0] == 'Matern52': kernel = gpflow.kernels.Matern52(input_dim=dims) \n",
    "        if kern[0] == 'RBF':      kernel = gpflow.kernels.RBF(input_dim=dims) \n",
    "        kernel.variance.prior = gpflow.priors.Gamma(scale=1,shape=shape)\n",
    "        if len(kern) == 2 and kern[1] == 'Linear':\n",
    "            linear = gpflow.kernels.Linear(input_dim=dims)\n",
    "            linear.variance.prior = gpflow.priors.Gamma(scale=1,shape=shape)\n",
    "            kernel += linear\n",
    "    return kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Moved\n",
    "# create x and y arrays\n",
    "def x_and_y(x, y):\n",
    "    change = {'decrease':     2,\n",
    "              'constant':     1, \n",
    "              'increase':     0,\n",
    "              'fewer':        2,\n",
    "              'same':         1,\n",
    "              'more':         0,\n",
    "              'not_increase': 1}\n",
    "    x = np.array(x)\n",
    "    y = np.array(pd.Series(y).replace(change).values.astype('int64')).reshape(y.shape[0], 1)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Moved\n",
    "# get bin edges and likelihood\n",
    "def create_likelihood(y):\n",
    "    bin_edges = np.array(np.arange(np.unique(y).size + 1), dtype=float)\n",
    "    # Need to check in on this, tutorial does the below which ends up with negative bins\n",
    "    # bin_edges = bin_edges - bin_edges.mean()\n",
    "    bin_edges = bin_edges - .5\n",
    "    return Ordinal(bin_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Moved\n",
    "# build a model with this likelihood\n",
    "def build_model(x_train, y_train, likelihood, kernel):\n",
    "    gaussian_model = gpflow.models.VGP(tf.cast(x_train, tf.float64),\n",
    "                                       y_train, \n",
    "                                       kern=kernel,\n",
    "                                       likelihood=likelihood)\n",
    "    # fit the model\n",
    "    gpflow.train.ScipyOptimizer().minimize(gaussian_model)\n",
    "    return gaussian_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Moved\n",
    "def predictive_density(model, x):\n",
    "    ys = np.arange(np.max(model.Y.value+1)).reshape([-1, 1])\n",
    "    x_new_vec = x*np.ones_like(ys)\n",
    "    # for predict_density x and y need to have the same number of rows\n",
    "    dens = np.exp(model.predict_density(x_new_vec, ys))\n",
    "    return dens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Moved\n",
    "# get predictive densities\n",
    "def test_model(model, x_test):\n",
    "    densities = []\n",
    "    # Predictive density for a single input x\n",
    "    for x in x_test:\n",
    "        densities.append(predictive_density(model, x))\n",
    "    return densities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Not used anymore\n",
    "# get accuracy\n",
    "def accuracy(y_test, densities):\n",
    "    score = 0\n",
    "    for index, y in enumerate(y_test):\n",
    "        if y == np.argmax(densities[index]): score += 1\n",
    "    return score/len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Moved\n",
    "# multiclass ROC\n",
    "def multiclass_roc_auc_score(y_test, y_pred, average=\"macro\"):\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(y_test)\n",
    "    y_test = lb.transform(y_test)\n",
    "    y_pred = lb.transform(y_pred)\n",
    "    return roc_auc_score(y_test, y_pred, average=average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure out the mse\n",
    "## Moved\n",
    "def scale_pred(pred):\n",
    "    factor = 1/sum(pred)\n",
    "    scaled = []\n",
    "    for p in pred:\n",
    "        scaled.append(p * factor)\n",
    "    return tuple(scaled)\n",
    "\n",
    "## Abstracted out, assuming true y_test_dist is passed in\n",
    "def calc_errors(x_test_all, densities, agg_level, dist):\n",
    "    mapping = {0: 'increase',\n",
    "               1: 'constant/not increase',\n",
    "               2: 'decrease'}\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    true_class = []\n",
    "    pred_class = []\n",
    "    # true then pred\n",
    "    confusion = defaultdict(lambda: defaultdict(int))\n",
    "    for index, x in enumerate(x_test_all):\n",
    "        pred = tuple([p for [p] in densities[index]])\n",
    "        pred = scale_pred(pred)\n",
    "        x = tuple(x)\n",
    "        true_info = noc_dict[dist][x]\n",
    "        noc = true_info['noc']\n",
    "        if len(pred) == 3: true_dist = true_info['share']\n",
    "        else:              true_dist = true_info['share_binned']\n",
    "        y_true.append(true_dist)\n",
    "        y_pred.append(pred)\n",
    "        y_t = np.argmax(true_dist)\n",
    "        y_p = np.argmax(pred)\n",
    "        true_class.append(y_t)\n",
    "        pred_class.append(y_p)\n",
    "        confusion[mapping[y_t]][mapping[y_p]] += 1\n",
    "        \n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    roc = multiclass_roc_auc_score(true_class, pred_class)\n",
    "    return mse, mae, roc, confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do cross validation\n",
    "def cv(x, y, x_all, y_all, kern, agg_level, dist, group):\n",
    "    if agg_level == 'ind': x_all = x_all.drop(['noc', 'participant.id'], axis=1)\n",
    "    x_all = np.asarray(x_all)\n",
    "    dims = len(x[0])\n",
    "    kf = GroupKFold(n_splits=5)\n",
    "    scores = []\n",
    "#     results = []\n",
    "    mse = []\n",
    "    mae = []\n",
    "    roc = []\n",
    "    total_confusion = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "    for train_index, test_index in kf.split(x, groups=group):\n",
    "        start = time.time()\n",
    "        x_train, x_test = x[train_index], x[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        x_test_all = x_all[test_index]\n",
    "        unique, unique_indices = np.unique(x_test, axis=0, return_index=True)        \n",
    "        kernel = get_kern(kern, dims, len(np.unique(y)))\n",
    "        likelihood = create_likelihood(y_all)\n",
    "        model = build_model(x_train, y_train, likelihood, kernel)\n",
    "        densities = test_model(model, [x_test[i] for i in unique_indices])\n",
    "        scores.append(accuracy([y_test[i] for i in unique_indices], densities))\n",
    "        mse_error, mae_error, roc_error, confusion = calc_errors([x_test_all[i] for i in unique_indices], \n",
    "                                                                 densities, \n",
    "                                                                 agg_level, \n",
    "                                                                 dist)\n",
    "        mse.append(mse_error)\n",
    "        mae.append(mae_error)\n",
    "        roc.append(roc_error)\n",
    "        for y_t in confusion:\n",
    "            for y_p in confusion[y_t]:\n",
    "                total_confusion[y_t][y_p] += confusion[y_t][y_p]\n",
    "#         results.append(create_results([x_test[i] for i in unique_indices], densities))\n",
    "        end = time.time()\n",
    "        print('Fold tested in (sec):', end - start)\n",
    "        del kernel, likelihood, model\n",
    "\n",
    "    return {'Avg. score':  sum(scores)/len(scores),\n",
    "            'Avg. mse':    sum(mse)/len(mse),\n",
    "            'Avg. mae':    sum(mae)/len(mae),\n",
    "            'Avg. roc':    sum(roc)/len(roc),\n",
    "            'Confusion':   dict(total_confusion),\n",
    "            'All scores':  scores,\n",
    "            'All mse':     mse,\n",
    "            'All mae':     mae,\n",
    "            'All roc':     roc}\n",
    "#             'All results': results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tester(model, save_path):\n",
    "    # results will be saved under gp_results/{save_path}\n",
    "    def run_test(scaler, normal):\n",
    "        start = time.time()\n",
    "        x, y = x_and_y(cleaned_x, y_all)\n",
    "        scale_name = params\n",
    "        if scaler:\n",
    "            scale_name += '_' + scaler.__name__\n",
    "            x = scaler(x)\n",
    "        if normal: \n",
    "            x = normalize(x)\n",
    "            scale_name += '_' + normalize.__name__\n",
    "        print('Testing:', scale_name)\n",
    "        result = cv(x, y, x_all, y_all, kern, agg_level, dist, group)\n",
    "        end = time.time()\n",
    "        print('Accuracy:', result['Avg. score'])\n",
    "        print('MSE:', result['Avg. mse'])\n",
    "        print('MAE:', result['Avg. mae'])\n",
    "        print('ROC:', result['Avg. roc'])\n",
    "        print('Confusion:', result['Confusion'])\n",
    "        print('Time elapsed (sec):', end - start)\n",
    "        pickle_results(result, scale_name)\n",
    "        print('Results saved to disk')\n",
    "        \n",
    "    params = '/'.join(['full_model', 'combined_kernel', name])\n",
    "    scales = [robust_scale, scale]\n",
    "    if agg_level == 'agg': \n",
    "        group = agg_nocs\n",
    "    else:\n",
    "        cleaned_x = x_all.drop(['noc', 'participant.id'], axis=1)\n",
    "        group = x_all['noc']\n",
    "#     for scaler in scales:\n",
    "#         for normal in range(2):\n",
    "#             run_test(scaler, normal)\n",
    "    run_test(scale, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickle_results(results, params):\n",
    "    with open('../gp_results/{}.pkl'.format(params), 'wb') as f:\n",
    "        pickle.dump(results, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brookfield",
   "language": "python",
   "name": "brookfield"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
